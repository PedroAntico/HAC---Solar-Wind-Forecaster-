"""
HAC++ Model: Heliospheric Accumulated Coupling - PRODU√á√ÉO FINAL
Script robusto para dados OMNI reais com tratamento completo de erros
"""
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# ============================
# 0. NORMALIZA√á√ÉO DE NOMES OMNI (CR√çTICO)
# ============================
def normalize_omni_columns(df):
    """
    NORMALIZA√á√ÉO ROBUSTA DE NOMES OMNI
    Garante nomes consistentes independente do formato
    """
    # Mapeamento completo de nomes OMNI
    column_map = {
        # Velocidade
        'flow_speed': 'speed',
        'V': 'speed', 
        'vx': 'speed',
        'proton_speed': 'speed',
        'velocity': 'speed',
        
        # Componente Bz
        'bz': 'bz_gsm',
        'bz_gsm': 'bz_gsm',
        'bz_gse': 'bz_gsm',
        'Bz_GSM': 'bz_gsm',
        'Bz_GSE': 'bz_gsm',
        'IMF_Bz': 'bz_gsm',
        
        # Densidade
        'density': 'density',
        'np': 'density',
        'proton_density': 'density',
        'Np': 'density',
        
        # Componentes Bx, By
        'bx': 'bx_gsm',
        'bx_gsm': 'bx_gsm',
        'by': 'by_gsm',
        'by_gsm': 'by_gsm',
        
        # Magnitude B
        'bt': 'bt',
        'B': 'bt',
        'B_total': 'bt',
        'IMF_B': 'bt',
        
        # Timestamp
        'time_tag': 'time_tag',
        'Time': 'time_tag',
        'timestamp': 'time_tag'
    }
    
    # Criar novo DataFrame com nomes normalizados
    normalized_df = pd.DataFrame()
    
    # Copiar todas as colunas existentes primeiro
    for col in df.columns:
        if col in column_map:
            normalized_name = column_map[col]
            normalized_df[normalized_name] = df[col]
        else:
            normalized_df[col] = df[col]
    
    # Verificar colunas obrigat√≥rias
    required = ['speed', 'bz_gsm', 'density', 'time_tag']
    missing = [c for c in required if c not in normalized_df.columns]
    
    if missing:
        print(f"‚ö†Ô∏è  Colunas ausentes: {missing}")
        print(f"   Colunas dispon√≠veis: {list(normalized_df.columns)}")
        
        # Tentar criar colunas faltantes
        if 'speed' in missing:
            # Tentar calcular de outras colunas de velocidade
            for vel_col in ['vx', 'vy', 'vz', 'Vx', 'Vy', 'Vz']:
                if vel_col in normalized_df.columns:
                    normalized_df['speed'] = np.sqrt(
                        normalized_df.get('vx', 0)**2 + 
                        normalized_df.get('vy', 0)**2 + 
                        normalized_df.get('vz', 0)**2
                    )
                    break
        
        # Verificar novamente
        missing = [c for c in required if c not in normalized_df.columns]
        if missing:
            raise ValueError(f"‚ùå COLUNAS OBRIGAT√ìRIAS AUSENTES: {missing}")
    
    return normalized_df

# ============================
# CONFIGURA√á√ÉO F√çSICA CALIBRADA
# ============================
class HACPhysicsConfig:
    """Configura√ß√£o f√≠sica validada para dados OMNI reais"""
    
    # TEMPOS CARACTER√çSTICOS (horas)
    TAU_RING_CURRENT = 3.0      # Tempo de decaimento da corrente de anel
    TAU_SUBSTORM = 1.5          # Tempo de inje√ß√£o por subtempestades  
    TAU_IONOSPHERE = 0.5        # Tempo de resposta ionosf√©rica
    
    # PAR√ÇMETROS DE SATURA√á√ÉO F√çSICA
    E_FIELD_SATURATION = 15.0   # mV/m - Satura√ß√£o OBSERVACIONAL
    KP_SATURATION = 8.0         # Satura√ß√£o do √≠ndice Kp
    RING_CURRENT_MAX = 500.0    # nT - Satura√ß√£o da corrente de anel
    
    # COEFICIENTES DE PARTICIONAMENTO (soma = 1.0)
    ALPHA_RING = 0.4           # Fra√ß√£o para corrente de anel
    ALPHA_SUBSTORM = 0.3       # Fra√ß√£o para subtempestades
    ALPHA_IONOSPHERE = 0.3     # Fra√ß√£o para ionosfera
    
    # PAR√ÇMETROS N√ÉO LINEARES
    BETA_NONLINEAR = 1.5       # Expoente de resposta n√£o linear
    COUPLING_THRESHOLD = 5.0   # mV/m - Limiar para n√£o-linearidade
    
    # ESCALAS OPERACIONAIS
    HAC_SCALE_MAX = 300.0
    KP_SCALE = 9.0
    
    # LIMITES F√çSICOS
    VSW_MIN, VSW_MAX = 200, 1500      # km/s
    DENSITY_MIN, DENSITY_MAX = 0.1, 100  # cm‚Åª¬≥
    BZ_MIN, BZ_MAX = -100, 100        # nT

# ============================
# 1. CARREGAMENTO ROBUSTO DE DADOS OMNI
# ============================
class RobustOMNIProcessor:
    """Processador robusto para dados OMNI reais"""
    
    @staticmethod
    def load_and_clean(filepath, max_interpolation=3):
        """
        Carrega, normaliza e limpa dados OMNI
        """
        print(f"üì• Carregando {filepath}...")
        
        try:
            with open(filepath, 'r') as f:
                data = json.load(f)
        except FileNotFoundError:
            print(f"‚ùå Arquivo n√£o encontrado: {filepath}")
            return None
        except json.JSONDecodeError as e:
            print(f"‚ùå Erro JSON: {e}")
            return None
        
        # Criar DataFrame
        headers = data[0]
        df = pd.DataFrame(data[1:], columns=headers)
        
        # NORMALIZA√á√ÉO CR√çTICA DE NOMES (antes de qualquer coisa)
        df = normalize_omni_columns(df)
        
        # Converter timestamp
        df['time_tag'] = pd.to_datetime(df['time_tag'], errors='coerce')
        df = df.sort_values('time_tag').reset_index(drop=True)
        
        # Converter para num√©rico
        numeric_cols = [col for col in df.columns if col != 'time_tag']
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # LIMPEZA EM 4 ETAPAS
        df = RobustOMNIProcessor._clean_dataframe(df, max_interpolation)
        
        print(f"   ‚úÖ {len(df)} pontos limpos")
        return df
    
    @staticmethod
    def _clean_dataframe(df, max_interpolation):
        """Pipeline completo de limpeza"""
        # 1. REMOVER INF/NAN EXPL√çCITOS
        df = df.replace([np.inf, -np.inf], np.nan)
        
        # 2. APLICAR LIMITES F√çSICOS
        config = HACPhysicsConfig()
        if 'speed' in df.columns:
            df['speed'] = df['speed'].clip(lower=config.VSW_MIN, upper=config.VSW_MAX)
        if 'density' in df.columns:
            df['density'] = df['density'].clip(lower=config.DENSITY_MIN, upper=config.DENSITY_MAX)
        if 'bz_gsm' in df.columns:
            df['bz_gsm'] = df['bz_gsm'].clip(lower=config.BZ_MIN, upper=config.BZ_MAX)
        
        # 3. INTERPOLA√á√ÉO INTELIGENTE
        cols_to_interpolate = ['bz_gsm', 'speed', 'density']
        for col in cols_to_interpolate:
            if col in df.columns:
                # Interpolar gaps pequenos
                df[col] = df[col].interpolate(
                    method='linear', 
                    limit=max_interpolation,
                    limit_direction='both'
                )
        
        # 4. REMO√á√ÉO FINAL DE NaN
        critical_cols = ['speed', 'bz_gsm', 'density']
        df_clean = df.dropna(subset=critical_cols).copy()
        
        # Estat√≠sticas
        original_len = len(df)
        clean_len = len(df_clean)
        retention = clean_len / original_len * 100 if original_len > 0 else 0
        
        if retention < 80:
            print(f"‚ö†Ô∏è  Reten√ß√£o baixa: {retention:.1f}% ({clean_len}/{original_len})")
        
        return df_clean
    
    @staticmethod
    def merge_datasets(mag_df, plasma_df):
        """Fus√£o robusta de datasets"""
        if mag_df is None or plasma_df is None:
            return None
        
        # Fus√£o por tempo
        df = pd.merge(mag_df, plasma_df, on='time_tag', how='outer')
        df = df.sort_values('time_tag').reset_index(drop=True)
        
        # Garantir colunas cr√≠ticas
        critical_cols = ['speed', 'bz_gsm', 'density']
        for col in critical_cols:
            if col in df.columns:
                # Preencher NaN com valores seguros
                if col == 'speed':
                    df[col] = df[col].fillna(400)  # km/s default
                elif col == 'bz_gsm':
                    df[col] = df[col].fillna(0)    # nT default
                elif col == 'density':
                    df[col] = df[col].fillna(5)    # cm‚Åª¬≥ default
        
        return df

# ============================
# 2. C√ÅLCULO DE CAMPOS F√çSICOS (SEMPRE SEGURO)
# ============================
class PhysicalFieldsCalculator:
    """Calcula campos f√≠sicos com prote√ß√£o total contra NaN"""
    
    @staticmethod
    def compute_all_fields(df):
        """
        Calcula TODOS os campos f√≠sicos necess√°rios
        SEM NUNCA GERAR NaN
        """
        df = df.copy()
        
        # 1. GARANTIR DADOS DE ENTRADA (CR√çTICO)
        bz = df['bz_gsm'].fillna(0).values
        v = df['speed'].fillna(400).values
        
        # 2. CAMPO EL√âTRICO BRUTO (com prote√ß√£o)
        # E = -Bz * V (apenas quando Bz < 0)
        bz_negative = np.maximum(0, -bz)  # Converte Bz<0 para positivo, Bz>=0 para 0
        df['E_field_raw'] = bz_negative * v * 1e-3  # mV/m
        
        # 3. SATURA√á√ÉO F√çSICA (CLIPPING, n√£o tanh!)
        config = HACPhysicsConfig()
        df['E_field_saturated'] = np.clip(
            df['E_field_raw'].values,
            0,
            config.E_FIELD_SATURATION
        )
        
        # 4. RESPOSTA N√ÉO LINEAR (ap√≥s satura√ß√£o)
        threshold = config.COUPLING_THRESHOLD
        beta = config.BETA_NONLINEAR
        
        e_saturated = df['E_field_saturated'].values
        coupling = np.zeros_like(e_saturated)
        
        # Regi√£o linear (abaixo do limiar)
        mask_linear = e_saturated <= threshold
        coupling[mask_linear] = e_saturated[mask_linear]
        
        # Regi√£o n√£o linear (acima do limiar)
        mask_nonlinear = e_saturated > threshold
        if np.any(mask_nonlinear):
            normalized = e_saturated[mask_nonlinear] / threshold
            coupling[mask_nonlinear] = threshold * (normalized ** beta)
        
        df['coupling_nonlinear'] = coupling
        
        # 5. SINAL DE ACOPLAMENTO (0 quando Bz positivo)
        # CORRE√á√ÉO CR√çTICA: usar bz original, n√£o bz_negative
        coupling_signal = np.where(bz < 0, coupling, 0.0)
        df['coupling_signal'] = coupling_signal
        
        # 6. VALIDA√á√ÉO
        print(f"   ‚Ä¢ E-field m√°ximo: {df['E_field_raw'].max():.1f} mV/m")
        print(f"   ‚Ä¢ E-field saturado: {df['E_field_saturated'].max():.1f} mV/m")
        print(f"   ‚Ä¢ Sinal acoplamento: {df['coupling_signal'].max():.1f}")
        
        # Garantir nenhum NaN
        for col in ['E_field_raw', 'E_field_saturated', 'coupling_signal']:
            if df[col].isna().any():
                df[col] = df[col].fillna(0)
                print(f"‚ö†Ô∏è  NaN corrigido em {col}")
        
        return df

# ============================
# 3. MODELO HAC+ CORRIGIDO (SEM NaN, SEM SATURA√á√ÉO)
# ============================
class ProductionHACModel:
    """Modelo HAC+ de produ√ß√£o com f√≠sica correta"""
    
    def __init__(self, config=None):
        self.config = config or HACPhysicsConfig()
        self.results = {}
    
    def compute_hac_system(self, df):
        """
        Sistema HAC+ completo com tratamento num√©rico robusto
        """
        print("\n‚ö° Calculando sistema HAC+...")
        
        # Extrair dados com prote√ß√£o
        times = pd.to_datetime(df['time_tag']).values
        coupling = df['coupling_signal'].fillna(0).values
        Bz = df['bz_gsm'].fillna(0).values
        
        # 1. DELTA-T SEGURO
        dt = self._safe_deltat(times)
        
        # 2. INICIALIZAR RESERVAT√ìRIOS
        n = len(times)
        hac_ring = np.zeros(n)
        hac_substorm = np.zeros(n)
        hac_ionosphere = np.zeros(n)
        
        # 3. CONSTANTES DE TEMPO (segundos)
        tau_rc = self.config.TAU_RING_CURRENT * 3600
        tau_sub = self.config.TAU_SUBSTORM * 3600
        tau_ion = self.config.TAU_IONOSPHERE * 3600
        
        # 4. SIMULA√á√ÉO TEMPORAL (PROTEGIDA)
        print("   Simulando reservat√≥rios...")
        for i in range(1, n):
            # Fatores de decaimento
            alpha_rc = np.exp(-dt[i] / tau_rc) if dt[i] > 0 else 0
            alpha_sub = np.exp(-dt[i] / tau_sub) if dt[i] > 0 else 0
            alpha_ion = np.exp(-dt[i] / tau_ion) if dt[i] > 0 else 0
            
            # Inje√ß√£o (garantida n√£o-NaN)
            injection = coupling[i] if not np.isnan(coupling[i]) else 0
            
            # EQUA√á√ïES CORRIGIDAS (com pondera√ß√£o)
            hac_ring[i] = alpha_rc * hac_ring[i-1] + self.config.ALPHA_RING * injection * dt[i]
            hac_substorm[i] = alpha_sub * hac_substorm[i-1] + self.config.ALPHA_SUBSTORM * injection * dt[i]
            hac_ionosphere[i] = alpha_ion * hac_ionosphere[i-1] + self.config.ALPHA_IONOSPHERE * injection * dt[i]
        
        # 5. COMBINA√á√ÉO PONDERADA (CORRE√á√ÉO CR√çTICA)
        hac_total = (
            self.config.ALPHA_RING * hac_ring +
            self.config.ALPHA_SUBSTORM * hac_substorm +
            self.config.ALPHA_IONOSPHERE * hac_ionosphere
        )
        
        # 6. NORMALIZA√á√ÉO SEGURA
        hac_total = self._safe_normalization(hac_total)
        
        # 7. ARMAZENAR
        self.results.update({
            'time': times,
            'HAC_total': hac_total,
            'HAC_ring': hac_ring,
            'HAC_substorm': hac_substorm,
            'HAC_ionosphere': hac_ionosphere,
            'Bz': Bz,
            'coupling_signal': coupling
        })
        
        # 8. VALIDA√á√ÉO
        self._validate_output(hac_total)
        
        return hac_total
    
    def _safe_deltat(self, times):
        """Calcula delta-t com prote√ß√£o"""
        n = len(times)
        dt = np.full(n, 60.0)  # Default 60s
        
        if n > 1:
            for i in range(1, n):
                try:
                    delta = (times[i] - times[i-1]).total_seconds()
                    dt[i] = max(delta, 1.0)
                except:
                    dt[i] = 60.0
            
            dt[0] = dt[1] if n > 1 else 60.0
        
        return dt
    
    def _safe_normalization(self, values):
        """Normaliza√ß√£o que NUNCA gera NaN"""
        # Encontrar m√°ximo ignorando NaN
        max_val = np.nanmax(values) if len(values) > 0 else 1.0
        
        if max_val > 0:
            normalized = values / max_val * self.config.HAC_SCALE_MAX
        else:
            normalized = np.zeros_like(values)
        
        # Prote√ß√£o final
        normalized = np.nan_to_num(normalized, nan=0.0, posinf=self.config.HAC_SCALE_MAX, neginf=0.0)
        
        print(f"   ‚Ä¢ HAC m√°ximo: {np.max(normalized):.1f}")
        print(f"   ‚Ä¢ HAC m√©dio: {np.mean(normalized):.1f}")
        
        return normalized
    
    def _validate_output(self, hac_values):
        """Valida√ß√£o rigorosa dos resultados"""
        # Verificar NaN
        nan_count = np.sum(np.isnan(hac_values))
        if nan_count > 0:
            print(f"‚ùå ERRO CR√çTICO: {nan_count} NaN em HAC")
            raise ValueError("NaN detectado em HAC")
        
        # Verificar valores f√≠sicos
        if np.max(hac_values) > self.config.HAC_SCALE_MAX * 1.5:
            print(f"‚ö†Ô∏è  AVISO: HAC excedeu escala ({np.max(hac_values):.1f})")
        
        print("   ‚úÖ Valida√ß√£o passada")
    
    def predict_storm_indicators(self, hac_values):
        """
        Predi√ß√£o robusta de indicadores de tempestade
        """
        print("\nüåç Predizendo indicadores...")
        
        # 1. Kp COM SATURA√á√ÉO
        kp_pred = self.config.KP_SCALE * np.tanh(
            hac_values / self.config.HAC_SCALE_MAX * 2
        )
        
        # 2. Dst EQUIVALENTE
        dst_pred = -self.config.RING_CURRENT_MAX * (
            hac_values / self.config.HAC_SCALE_MAX
        ) ** 1.3
        
        # 3. CLASSIFICA√á√ÉO NOAA
        storm_levels = []
        for h in hac_values:
            if h < 50:
                level = "Quiet"
            elif h < 100:
                level = "G1"
            elif h < 150:
                level = "G2"
            elif h < 200:
                level = "G3"
            elif h < 250:
                level = "G4"
            else:
                level = "G5"
            storm_levels.append(level)
        
        # 4. ARMAZENAR
        self.results.update({
            'Kp_pred': kp_pred,
            'Dst_pred': dst_pred,
            'Storm_level': storm_levels
        })
        
        # 5. ESTAT√çSTICAS
        g4g5_count = sum(1 for l in storm_levels if l in ['G4', 'G5'])
        print(f"   ‚Ä¢ Kp m√°ximo: {np.max(kp_pred):.1f}")
        print(f"   ‚Ä¢ Dst m√≠nimo: {np.min(dst_pred):.1f} nT")
        print(f"   ‚Ä¢ Eventos G4/G5: {g4g5_count}")
        
        return kp_pred, dst_pred, storm_levels

# ============================
# 4. VISUALIZA√á√ÉO DE PRODU√á√ÉO
# ============================
class ProductionVisualizer:
    """Visualiza√ß√£o profissional para produ√ß√£o"""
    
    @staticmethod
    def create_final_dashboard(results, df, filename="hac_final_production.png"):
        """Cria dashboard final de produ√ß√£o"""
        print(f"\nüìà Criando dashboard: {filename}")
        
        # Verificar dados
        if len(results.get('HAC_total', [])) < 10:
            print("‚ùå Dados insuficientes")
            return None
        
        # Criar figura
        plt.style.use('default')
        fig, axes = plt.subplots(3, 2, figsize=(15, 10))
        fig.suptitle('HAC+ Model - Sistema Completo de Previs√£o', fontsize=14, fontweight='bold')
        
        # ===== PAINEL 1: HAC TOTAL =====
        ax1 = axes[0, 0]
        if 'HAC_total' in results:
            ax1.plot(results['time'], results['HAC_total'], 
                    color='#d62728', linewidth=2, label='HAC Total')
        
        # Thresholds
        colors = ['#2ecc71', '#f1c40f', '#e67e22', '#e74c3c', '#9b59b6']
        levels = [50, 100, 150, 200, 250]
        for lvl, col in zip(levels, colors):
            ax1.axhline(y=lvl, color=col, linestyle=':', alpha=0.5)
        
        ax1.set_ylabel('HAC Index', fontsize=10)
        ax1.set_title('A. Estado do Reservat√≥rio', fontsize=11)
        ax1.legend(loc='upper left')
        ax1.grid(True, alpha=0.3)
        ax1.set_ylim(0, 320)
        
        # ===== PAINEL 2: COMPONENTES =====
        ax2 = axes[0, 1]
        if all(k in results for k in ['HAC_ring', 'HAC_substorm', 'HAC_ionosphere']):
            ax2.plot(results['time'], results['HAC_ring'], label='Corrente de Anel', alpha=0.7)
            ax2.plot(results['time'], results['HAC_substorm'], label='Subtempestades', alpha=0.7)
            ax2.plot(results['time'], results['HAC_ionosphere'], label='Ionosfera', alpha=0.7)
        
        ax2.set_ylabel('Componentes HAC', fontsize=10)
        ax2.set_title('B. Particionamento de Energia', fontsize=11)
        ax2.legend(loc='upper left', fontsize=8)
        ax2.grid(True, alpha=0.3)
        
        # ===== PAINEL 3: Kp PREVISTO =====
        ax3 = axes[1, 0]
        if 'Kp_pred' in results:
            ax3.plot(results['time'], results['Kp_pred'], 
                    color='#e74c3c', linewidth=1.5, label='Kp previsto')
            ax3.axhline(y=8, color='red', linestyle='--', alpha=0.5, label='Satura√ß√£o')
        
        ax3.set_ylabel('√çndice Kp', fontsize=10)
        ax3.set_title('C. Atividade Geomagn√©tica Prevista', fontsize=11)
        ax3.legend(loc='upper left')
        ax3.grid(True, alpha=0.3)
        ax3.set_ylim(0, 9.5)
        
        # ===== PAINEL 4: Bz =====
        ax4 = axes[1, 1]
        if 'Bz' in results:
            ax4.plot(results['time'], results['Bz'], 
                    color='#2ecc71', linewidth=1, label='Bz')
            ax4.fill_between(results['time'], 0, results['Bz'],
                            where=(results['Bz'] < 0),
                            color='red', alpha=0.3, label='IMF Sul')
        
        ax4.axhline(y=0, color='black', linestyle='-', alpha=0.3)
        ax4.set_ylabel('Bz [nT]', fontsize=10)
        ax4.set_title('D. For√ßante do Vento Solar', fontsize=11)
        ax4.legend(loc='upper right')
        ax4.grid(True, alpha=0.3)
        
        # ===== PAINEL 5: ACOPLAMENTO =====
        ax5 = axes[2, 0]
        if 'coupling_signal' in results:
            ax5.plot(results['time'], results['coupling_signal'],
                    color='#9b59b6', linewidth=1, label='Acoplamento')
        
        ax5.set_ylabel('Acoplamento [mV/m]', fontsize=10)
        ax5.set_xlabel('Tempo (UTC)', fontsize=10)
        ax5.set_title('E. Sinal de Acoplamento Efetivo', fontsize=11)
        ax5.legend(loc='upper left')
        ax5.grid(True, alpha=0.3)
        
        # ===== PAINEL 6: VELOCIDADE =====
        ax6 = axes[2, 1]
        if 'speed' in df.columns:
            ax6.plot(df['time_tag'], df['speed'],
                    color='#3498db', linewidth=1, label='Velocidade')
        
        ax6.set_ylabel('V [km/s]', fontsize=10)
        ax6.set_xlabel('Tempo (UTC)', fontsize=10)
        ax6.set_title('F. Velocidade do Vento Solar', fontsize=11)
        ax6.legend(loc='upper left')
        ax6.grid(True, alpha=0.3)
        
        # Ajustar layout
        plt.tight_layout()
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"‚úÖ Dashboard salvo: {filename}")
        return fig

# ============================
# 5. RELAT√ìRIO FINAL
# ============================
class FinalReport:
    """Gera relat√≥rio final completo"""
    
    @staticmethod
    def generate_report(results, df, filename="hac_final_report.txt"):
        """Relat√≥rio final do sistema"""
        print("\n" + "="*70)
        print("üìä RELAT√ìRIO FINAL - SISTEMA HAC+")
        print("="*70)
        
        with open(filename, 'w') as f:
            f.write("="*60 + "\n")
            f.write("RELAT√ìRIO FINAL - SISTEMA HAC+ (PRODU√á√ÉO)\n")
            f.write("="*60 + "\n\n")
            
            # 1. INFORMA√á√ïES B√ÅSICAS
            f.write("1. INFORMA√á√ïES DO DATASET\n")
            f.write("-"*40 + "\n")
            f.write(f"Per√≠odo: {df['time_tag'].min()} a {df['time_tag'].max()}\n")
            f.write(f"Pontos totais: {len(df)}\n")
            f.write(f"Dura√ß√£o: {(df['time_tag'].max() - df['time_tag'].min()).total_seconds()/3600:.1f} horas\n\n")
            
            # 2. DADOS DE ENTRADA
            f.write("2. DADOS DE ENTRADA (estat√≠sticas)\n")
            f.write("-"*40 + "\n")
            stats_cols = ['speed', 'bz_gsm', 'density']
            for col in stats_cols:
                if col in df.columns:
                    f.write(f"{col:10s}: min={df[col].min():7.2f}, "
                           f"max={df[col].max():7.2f}, "
                           f"mean={df[col].mean():7.2f}\n")
            f.write("\n")
            
            # 3. RESULTADOS HAC
            f.write("3. RESULTADOS DO MODELO HAC+\n")
            f.write("-"*40 + "\n")
            
            if 'HAC_total' in results:
                hac = results['HAC_total']
                f.write(f"HAC m√°ximo: {np.max(hac):.2f}\n")
                f.write(f"HAC m√≠nimo: {np.min(hac):.2f}\n")
                f.write(f"HAC m√©dio:  {np.mean(hac):.2f}\n")
                f.write(f"Desvio padr√£o: {np.std(hac):.2f}\n\n")
                
                # Distribui√ß√£o de n√≠veis
                if 'Storm_level' in results:
                    levels = results['Storm_level']
                    total = len(levels)
                    f.write("Distribui√ß√£o de n√≠veis:\n")
                    for lvl in ['Quiet', 'G1', 'G2', 'G3', 'G4', 'G5']:
                        count = sum(1 for x in levels if x == lvl)
                        pct = count/total*100 if total > 0 else 0
                        f.write(f"  {lvl:6s}: {count:4d} pontos ({pct:5.1f}%)\n")
            
            # 4. PREDI√á√ïES
            f.write("\n4. PREDI√á√ïES GEOMAGN√âTICAS\n")
            f.write("-"*40 + "\n")
            
            if 'Kp_pred' in results:
                kp = results['Kp_pred']
                f.write(f"Kp m√°ximo previsto: {np.max(kp):.2f}\n")
                f.write(f"Kp m√©dio previsto:  {np.mean(kp):.2f}\n")
            
            if 'Dst_pred' in results:
                dst = results['Dst_pred']
                f.write(f"Dst m√≠nimo previsto: {np.min(dst):.2f} nT\n")
                f.write(f"Dst m√©dio previsto:  {np.mean(dst):.2f} nT\n")
            
            # 5. STATUS FINAL
            f.write("\n5. STATUS FINAL DO SISTEMA\n")
            f.write("-"*40 + "\n")
            
            if 'Storm_level' in results and len(results['Storm_level']) > 0:
                current_level = results['Storm_level'][-1]
                f.write(f"N√≠vel atual: {current_level}\n")
                
                if current_level in ['G4', 'G5']:
                    f.write("üö® ALERTA: Condi√ß√µes de tempestade severa\n")
                elif current_level == 'G3':
                    f.write("‚ö†Ô∏è  ALERTA: Tempestade forte\n")
                elif current_level == 'G2':
                    f.write("üì¢ ATEN√á√ÉO: Tempestade moderada\n")
                elif current_level == 'G1':
                    f.write("üìã MONITORAMENTO: Tempestade menor\n")
                else:
                    f.write("‚úÖ Condi√ß√µes quietas\n")
            
            f.write(f"\nRelat√≥rio gerado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("="*60 + "\n")
        
        print(f"üìù Relat√≥rio final salvo: {filename}")
        
        # Resumo no console
        if 'Storm_level' in results and len(results['Storm_level']) > 0:
            current_level = results['Storm_level'][-1]
            current_hac = results['HAC_total'][-1] if 'HAC_total' in results else 0
            
            print(f"\nüéØ STATUS ATUAL: HAC = {current_hac:.1f} ‚Üí {current_level}")
            
            if current_level in ['G4', 'G5']:
                print("   üö® ALERTA DE TEMPESTADE SEVERA")
            elif current_level == 'G3':
                print("   ‚ö†Ô∏è  ALERTA DE TEMPESTADE FORTE")
        
        print("\n" + "="*70)

# ============================
# 6. PIPELINE PRINCIPAL (CORRIGIDO)
# ============================
def main():
    """Pipeline principal - PRODU√á√ÉO FINAL"""
    print("\n" + "="*70)
    print("üöÄ HAC++ MODEL - SISTEMA DE PRODU√á√ÉO FINAL")
    print("="*70)
    print("Com normaliza√ß√£o OMNI completa e f√≠sica corrigida")
    print("="*70)
    
    # Configurar caminhos
    MAG_FILE = "data/mag-7-day.json"
    PLASMA_FILE = "data/plasma-7-day.json"
    
    # 1. CARREGAR E NORMALIZAR DADOS
    print("\nüì• CARREGANDO DADOS OMNI (com normaliza√ß√£o)...")
    
    processor = RobustOMNIProcessor()
    mag_df = processor.load_and_clean(MAG_FILE)
    plasma_df = processor.load_and_clean(PLASMA_FILE)
    
    if mag_df is None or plasma_df is None:
        print("‚ùå Falha no carregamento")
        return
    
    # 2. FUS√ÉO
    print("\nüîß FUNDINDO DATASETS...")
    df = processor.merge_datasets(mag_df, plasma_df)
    
    if df is None or len(df) < 10:
        print("‚ùå Dados insuficientes")
        return
    
    print(f"   Dataset final: {len(df)} pontos")
    
    # 3. CAMPOS F√çSICOS (SEMPRE SEGURO)
    print("\n‚ö° CALCULANDO CAMPOS F√çSICOS...")
    calculator = PhysicalFieldsCalculator()
    df = calculator.compute_all_fields(df)
    
    # 4. MODELO HAC+
    print("\nüßÆ EXECUTANDO MODELO HAC+ (produ√ß√£o)...")
    model = ProductionHACModel()
    hac_values = model.compute_hac_system(df)
    
    # 5. PREDI√á√ÉO
    print("\nüåç GERANDO PREDI√á√ïES...")
    kp_pred, dst_pred, storm_levels = model.predict_storm_indicators(hac_values)
    
    # 6. VISUALIZA√á√ÉO
    print("\nüìà CRIANDO VISUALIZA√á√ïES...")
    visualizer = ProductionVisualizer()
    visualizer.create_final_dashboard(model.results, df, "hac_production_final.png")
    
    # 7. RELAT√ìRIO
    print("\nüìä GERANDO RELAT√ìRIO FINAL...")
    reporter = FinalReport()
    reporter.generate_report(model.results, df)
    
    # 8. SALVAR RESULTADOS
    try:
        # Adicionar resultados ao DataFrame
        results_df = df.copy()
        for key, value in model.results.items():
            if key != 'time':
                results_df[key] = value
        
        # Salvar
        output_file = "hac_production_results.csv"
        results_df.to_csv(output_file, index=False)
        print(f"\nüíæ Resultados salvos: {output_file}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro ao salvar: {e}")
    
    # 9. STATUS FINAL
    print("\n" + "="*70)
    print("‚úÖ SISTEMA HAC++ - EXECU√á√ÉO CONCLU√çDA")
    print("="*70)
    
    if 'Storm_level' in model.results and len(model.results['Storm_level']) > 0:
        current_level = model.results['Storm_level'][-1]
        current_hac = model.results['HAC_total'][-1]
        
        print(f"\nüî¥ STATUS OPERACIONAL:")
        print(f"   HAC: {current_hac:.1f}")
        print(f"   N√≠vel: {current_level}")
        
        if 'Kp_pred' in model.results:
            print(f"   Kp previsto: {model.results['Kp_pred'][-1]:.1f}")
        
        print(f"\nüìÅ ARQUIVOS GERADOS:")
        print(f"   1. hac_production_final.png - Dashboard")
        print(f"   2. hac_production_results.csv - Dados")
        print(f"   3. hac_final_report.txt - Relat√≥rio")
    
    print("\n" + "="*70)

# ============================
# EXECU√á√ÉO
# ============================
if __name__ == "__main__":
    # Configurar display
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', 120)
    
    # Executar
    main()
