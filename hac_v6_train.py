#!/usr/bin/env python3
"""
hac_v6_train.py - CORRIGIDO
Training pipeline para HAC v6 Solar Wind Forecaster.

INTEGRA√á√ÉO COMPLETA:
1. HACFeatureBuilder (com escalonamento Y separado por vari√°vel)
2. PhysicalModelBuilder (com head f√≠sico e limites)
3. Pipeline de treino robusto para GitHub Free
"""

import os
import json
import gc
import psutil
from datetime import datetime
from typing import Dict, List, Any, Tuple
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import joblib
import tensorflow as tf
from sklearn.metrics import mean_absolute_error, mean_squared_error

from hac_v6_config import HACConfig
from hac_v6_features import HACFeatureBuilder
from hac_v6_models import create_model_builder


class HACTrainer:
    """Pipeline de treino completo para HAC v6 com f√≠sica correta."""
    
    def __init__(self, config_path: str = "config.yaml"):
        """Inicializa o trainer com configura√ß√£o e componentes."""
        print("=" * 60)
        print("üöÄ HAC v6 PHYSICAL TRAINER - GitHub Free Optimized")
        print("=" * 60)
        
        # 1. Carregar configura√ß√£o
        print("üì° Loading configuration...")
        self.config = HACConfig(config_path)
        
        # 2. Configurar ambiente para GitHub Free
        self._setup_github_free_environment()
        
        # 3. Inicializar componentes
        print("üîß Initializing feature builder...")
        self.feature_builder = HACFeatureBuilder(self.config)
        
        print("üß† Initializing model builder...")
        self.model_builder = create_model_builder(self.config.get_all())
        
        # 4. Configurar diret√≥rios
        self._setup_directories()
        
        # 5. Inicializar relat√≥rio
        self.train_report = self._initialize_report()
        
        print("‚úÖ Trainer initialized successfully")
        self._log_memory("After initialization")
    
    def _setup_github_free_environment(self):
        """Configura otimiza√ß√µes espec√≠ficas para GitHub Free."""
        # Desativar GPU completamente
        tf.config.set_visible_devices([], 'GPU')
        
        # Configurar threads do TensorFlow
        tf.config.threading.set_intra_op_parallelism_threads(2)
        tf.config.threading.set_inter_op_parallelism_threads(2)
        
        # Usar float32 para economia de mem√≥ria
        tf.keras.backend.set_floatx('float32')
        
        # Configurar aloca√ß√£o de mem√≥ria do TF
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            try:
                # Limitar uso de GPU se dispon√≠vel (para testes locais)
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)
            except RuntimeError as e:
                print(f"‚ö†Ô∏è  GPU config warning: {e}")
        
        print("‚öôÔ∏è  Configured for GitHub Free environment")
    
    def _setup_directories(self):
        """Cria diret√≥rios necess√°rios para o treino."""
        paths = self.config.get("paths")
        self.model_dir = paths["model_dir"]
        self.results_dir = paths["results_dir"]
        self.checkpoints_dir = os.path.join(self.model_dir, "checkpoints")
        
        # Criar diret√≥rios
        os.makedirs(self.model_dir, exist_ok=True)
        os.makedirs(self.results_dir, exist_ok=True)
        os.makedirs(self.checkpoints_dir, exist_ok=True)
        
        print(f"üìÅ Model dir: {self.model_dir}")
        print(f"üìÅ Results dir: {self.results_dir}")
    
    def _initialize_report(self) -> Dict:
        """Inicializa o relat√≥rio de treino."""
        return {
            "timestamp": datetime.utcnow().isoformat(),
            "config": {
                "horizons": self.config.get("horizons"),
                "targets": self.config.get("targets")["primary"],
                "lookback": self.config.get("training")["main_lookback"],
                "batch_size": self.config.get("training")["batch_size"],
                "max_epochs": self.config.get("training")["max_epochs"]
            },
            "physical_constraints": True,
            "github_free_optimized": True,
            "horizons": {},
            "resource_usage": {}
        }
    
    def _log_memory(self, stage: str):
        """Registra uso de mem√≥ria para monitoramento."""
        mem = psutil.virtual_memory()
        self.train_report["resource_usage"][stage] = {
            "percent": float(mem.percent),
            "available_gb": float(mem.available / 1e9),
            "used_gb": float(mem.used / 1e9)
        }
        
        # Log apenas se uso > 70% ou em pontos cr√≠ticos
        if mem.percent > 70 or stage in ["After horizon", "After training"]:
            print(f"   üß† {stage} - Mem: {mem.percent:.1f}% | "
                  f"Dispon√≠vel: {mem.available / 1e9:.1f} GB")
    
    def run(self):
        """Executa o pipeline completo de treino."""
        print("\n" + "=" * 60)
        print("üî• STARTING COMPLETE TRAINING PIPELINE")
        print("=" * 60)
        
        try:
            # 1. Construir datasets
            print("\nüìä STEP 1: Building datasets...")
            datasets = self.feature_builder.build_all()
            
            if not datasets:
                raise ValueError("‚ùå No datasets generated!")
            
            # 2. Configura√ß√µes de treino
            training_config = self.config.get("training")
            lookback = training_config["main_lookback"]
            horizons = self.config.get("horizons")
            targets = self.config.get("targets")["primary"]
            
            # Ajustes para GitHub Free
            batch_size = min(training_config["batch_size"], 32)
            max_epochs = min(training_config["max_epochs"], 50)
            
            print(f"\n‚öôÔ∏è  Training configuration:")
            print(f"   ‚Ä¢ Horizons: {horizons}")
            print(f"   ‚Ä¢ Targets: {targets}")
            print(f"   ‚Ä¢ Lookback: {lookback}")
            print(f"   ‚Ä¢ Batch size: {batch_size} (adjusted for GitHub Free)")
            print(f"   ‚Ä¢ Max epochs: {max_epochs} (adjusted for GitHub Free)")
            
            # 3. Treinar para cada horizonte
            trained_horizons = 0
            for horizon in horizons[:3]:  # Limitar a 3 horizontes no GitHub Free
                if horizon in datasets:
                    print(f"\n{'='*50}")
                    print(f"üéØ TRAINING HORIZON {horizon}h")
                    print(f"{'='*50}")
                    
                    success = self._train_single_horizon(
                        horizon=horizon,
                        dataset=datasets[horizon],
                        lookback=lookback,
                        batch_size=batch_size,
                        max_epochs=max_epochs,
                        targets=targets
                    )
                    
                    if success:
                        trained_horizons += 1
                    
                    # Limpar mem√≥ria entre horizontes
                    self._cleanup_between_horizons()
                else:
                    print(f"‚ö†Ô∏è  No data for horizon {horizon}h")
            
            # 4. Salvar relat√≥rio final
            if trained_horizons > 0:
                self._save_final_report()
                print(f"\nüéâ TRAINING COMPLETED! {trained_horizons} horizons trained")
            else:
                print("\n‚ùå No horizons were successfully trained")
            
            # 5. Resumo de recursos
            self._print_resource_summary()
            
        except MemoryError as e:
            print(f"\nüí• OUT OF MEMORY ERROR: {str(e)}")
            print("\nüîß Recommendations for GitHub Free:")
            print("   1. Reduce batch_size in config.yaml")
            print("   2. Reduce max_epochs")
            print("   3. Use fewer horizons")
            print("   4. Reduce lookback window")
            raise
        
        except Exception as e:
            print(f"\nüí• TRAINING FAILED: {str(e)}")
            import traceback
            traceback.print_exc()
            raise
    
    def _train_single_horizon(self, horizon: int, dataset: Dict,
                            lookback: int, batch_size: int,
                            max_epochs: int, targets: List[str]) -> bool:
        """Treina modelo para um √∫nico horizonte."""
        try:
            # 1. Preparar dados
            print(f"\nüì¶ Preparing data for horizon {horizon}h...")
            X = dataset["X"]
            y_scaled = dataset["y_scaled"]  # y j√° escalonado por vari√°vel
            y_raw = dataset["y_raw"]        # y original para m√©tricas
            
            print(f"   Dataset shape: X={X.shape}, y={y_scaled.shape}")
            
            # 2. Split dos dados
            print("üìä Splitting data...")
            X_train, y_train_scaled, X_val, y_val_scaled, X_test, y_test_scaled, y_test_raw = \
                self._split_data(X, y_scaled, y_raw)
            
            # 3. Construir modelo
            print("üî® Building physical model...")
            model = self._build_model_for_horizon(
                input_shape=(lookback, X.shape[2]),
                targets=targets,
                horizon=horizon
            )
            
            # 4. Criar callbacks
            callbacks = self._create_callbacks_for_horizon(horizon)
            
            # 5. Treinar modelo
            print(f"\nüî• Training model for horizon {horizon}h...")
            history = model.fit(
                X_train, y_train_scaled,
                validation_data=(X_val, y_val_scaled),
                epochs=max_epochs,
                batch_size=batch_size,
                callbacks=callbacks,
                verbose=1,
                workers=1,  # Reduzir para GitHub Free
                use_multiprocessing=False
            )
            
            # 6. Avaliar modelo
            print("\nüìà Evaluating model...")
            metrics = self._evaluate_model(
                model=model,
                X_test=X_test,
                y_test_scaled=y_test_scaled,
                y_test_raw=y_test_raw,
                horizon=horizon,
                targets=targets
            )
            
            # 7. Salvar artefatos
            self._save_horizon_artifacts(
                model=model,
                horizon=horizon,
                history=history.history,
                metrics=metrics,
                test_size=len(X_test)
            )
            
            # 8. Atualizar relat√≥rio
            self._update_horizon_report(horizon, metrics, len(X_train))
            
            return True
            
        except Exception as e:
            print(f"\n‚ùå Failed to train horizon {horizon}h: {str(e)}")
            return False
    
    def _split_data(self, X: np.ndarray, y_scaled: np.ndarray,
                   y_raw: np.ndarray) -> Tuple:
        """Divide os dados em treino, valida√ß√£o e teste."""
        n_total = len(X)
        
        # Usar splits do config
        val_split = min(self.config.get("training")["val_split"], 0.2)
        test_split = min(self.config.get("training")["test_split"], 0.2)
        
        n_val = int(n_total * val_split)
        n_test = int(n_total * test_split)
        n_train = n_total - n_val - n_test
        
        # Verificar tamanhos m√≠nimos
        if n_train < 100:
            print(f"‚ö†Ô∏è  Warning: Small training set ({n_train} samples)")
        
        print(f"   Split: Train={n_train}, Val={n_val}, Test={n_test}")
        
        # Split dos dados
        X_train = X[:n_train]
        y_train_scaled = y_scaled[:n_train]
        
        X_val = X[n_train:n_train + n_val]
        y_val_scaled = y_scaled[n_train:n_train + n_val]
        
        X_test = X[n_train + n_val:n_train + n_val + n_test]
        y_test_scaled = y_scaled[n_train + n_val:n_train + n_val + n_test]
        y_test_raw = y_raw[n_train + n_val:n_train + n_val + n_test]
        
        return X_train, y_train_scaled, X_val, y_val_scaled, X_test, y_test_scaled, y_test_raw
    
    def _build_model_for_horizon(self, input_shape: Tuple[int, int],
                               targets: List[str], horizon: int) -> tf.keras.Model:
        """Constr√≥i modelo f√≠sico para um horizonte espec√≠fico."""
        model_type = self.config.get("model", {}).get("type", "lstm")
        
        print(f"   Building {model_type} model for {targets}...")
        
        if model_type == "hybrid":
            model = self.model_builder.build_hybrid_model(input_shape, targets)
        elif model_type == "lightweight":
            model = self.model_builder.build_lightweight_model(input_shape, targets)
        else:  # Default: LSTM
            model = self.model_builder.build_lstm_model(input_shape, targets)
        
        # Resumo do modelo
        print(f"   Model built: {model.name}")
        print(f"   Input shape: {model.input_shape}")
        print(f"   Output shape: {model.output_shape}")
        print(f"   Parameters: {model.count_params():,}")
        
        return model
    
    def _create_callbacks_for_horizon(self, horizon: int) -> List:
        """Cria callbacks para o treino de um horizonte."""
        model_type = self.config.get("model", {}).get("type", "lstm")
        callbacks = self.model_builder.create_callbacks(horizon, model_type)
        
        # Adicionar callback customizado para monitoramento
        class ResourceMonitor(tf.keras.callbacks.Callback):
            def on_epoch_end(self, epoch, logs=None):
                if epoch % 5 == 0:
                    mem = psutil.virtual_memory()
                    print(f"      Epoch {epoch}: Mem {mem.percent:.1f}% | "
                          f"Loss: {logs.get('loss', 0):.4f} | "
                          f"Val Loss: {logs.get('val_loss', 0):.4f}")
        
        callbacks.append(ResourceMonitor())
        
        return callbacks
    
    def _evaluate_model(self, model: tf.keras.Model, X_test: np.ndarray,
                       y_test_scaled: np.ndarray, y_test_raw: np.ndarray,
                       horizon: int, targets: List[str]) -> Dict:
        """Avalia o modelo e retorna m√©tricas."""
        # 1. Avaliar no conjunto de teste (escalonado)
        test_metrics = model.evaluate(X_test, y_test_scaled, verbose=0)
        
        # 2. Fazer previs√µes
        y_pred_scaled = model.predict(X_test, verbose=0, batch_size=32)
        
        # 3. Dessecalizar previs√µes
        y_pred_raw = self._inverse_scale_predictions(
            y_pred_scaled, horizon, targets
        )
        
        # 4. Calcular m√©tricas nos valores reais
        metrics = self._calculate_metrics(y_test_raw, y_pred_raw, targets)
        
        # 5. Verificar limites f√≠sicos
        violations = self._check_physical_violations(y_pred_raw, targets)
        
        # 6. Log dos resultados
        print(f"\nüìä Evaluation results for horizon {horizon}h:")
        print(f"   ‚Ä¢ Test Loss: {test_metrics[0]:.4f}")
        print(f"   ‚Ä¢ MAE: {metrics['mae']:.4f}")
        print(f"   ‚Ä¢ RMSE: {metrics['rmse']:.4f}")
        
        if violations > 0:
            print(f"   ‚ö†Ô∏è  Physical violations: {violations}")
        else:
            print(f"   ‚úÖ All predictions respect physical limits")
        
        # Adicionar m√©tricas de teste
        metrics.update({
            "test_loss": float(test_metrics[0]),
            "physical_violations": violations,
            "test_samples": len(X_test)
        })
        
        return metrics
    
    def _inverse_scale_predictions(self, y_pred_scaled: np.ndarray,
                                 horizon: int, targets: List[str]) -> np.ndarray:
        """Dessecalona previs√µes usando os scalers Y por vari√°vel."""
        y_pred_raw = np.zeros_like(y_pred_scaled)
        
        # Obter scalers Y para este horizonte
        y_scalers = self.feature_builder.get_y_scalers(horizon)
        
        if not y_scalers:
            print(f"‚ö†Ô∏è  No Y scalers found for horizon {horizon}h")
            return y_pred_scaled
        
        # Dessecalonar cada vari√°vel separadamente
        for idx, var_name in enumerate(targets):
            if var_name in y_scalers:
                scaler = y_scalers[var_name]
                # Extrair apenas esta coluna
                y_single = y_pred_scaled[:, idx].reshape(-1, 1)
                # Dessecalonar
                y_descaled = scaler.inverse_transform(y_single)
                y_pred_raw[:, idx] = y_descaled.flatten()
            else:
                print(f"‚ö†Ô∏è  No scaler found for {var_name} at horizon {horizon}h")
                y_pred_raw[:, idx] = y_pred_scaled[:, idx]
        
        return y_pred_raw
    
    def _calculate_metrics(self, y_true: np.ndarray, y_pred: np.ndarray,
                          targets: List[str]) -> Dict:
        """Calcula m√©tricas de avalia√ß√£o."""
        metrics = {
            "mae": float(mean_absolute_error(y_true, y_pred)),
            "mse": float(mean_squared_error(y_true, y_pred)),
            "rmse": float(np.sqrt(mean_squared_error(y_true, y_pred)))
        }
        
        # M√©tricas por vari√°vel
        per_variable_metrics = {}
        for idx, var_name in enumerate(targets):
            y_true_var = y_true[:, idx]
            y_pred_var = y_pred[:, idx]
            
            per_variable_metrics[var_name] = {
                "mae": float(mean_absolute_error(y_true_var, y_pred_var)),
                "rmse": float(np.sqrt(mean_squared_error(y_true_var, y_pred_var)))
            }
        
        metrics["per_variable"] = per_variable_metrics
        
        return metrics
    
    def _check_physical_violations(self, y_pred: np.ndarray,
                                 targets: List[str]) -> int:
        """Conta viola√ß√µes de limites f√≠sicos nas previs√µes."""
        violations = 0
        
        # Limites f√≠sicos baseados no model builder
        physical_limits = {
            "V": (250, 1650),
            "Bz": (-40, 40),
            "n": (0, 100),
            "Bx": (-50, 50),
            "By": (-50, 50),
            "Bt": (0, 80)
        }
        
        for idx, var_name in enumerate(targets):
            if var_name in physical_limits:
                v_min, v_max = physical_limits[var_name]
                var_violations = np.sum((y_pred[:, idx] < v_min) | (y_pred[:, idx] > v_max))
                violations += int(var_violations)
                
                if var_violations > 0:
                    print(f"      ‚ö†Ô∏è  {var_name}: {int(var_violations)} violations")
        
        return violations
    
    def _save_horizon_artifacts(self, model: tf.keras.Model, horizon: int,
                              history: Dict, metrics: Dict, test_size: int):
        """Salva todos os artefatos de um horizonte."""
        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M")
        model_name = f"hac_physical_h{horizon}_{timestamp}"
        out_dir = os.path.join(self.model_dir, model_name)
        
        print(f"\nüíæ Saving artifacts for horizon {horizon}h...")
        print(f"   Directory: {out_dir}")
        
        # 1. Salvar modelo
        model_path = os.path.join(out_dir, "model.keras")
        model.save(model_path, save_format="keras")
        model_size_mb = os.path.getsize(model_path) / (1024 * 1024)
        print(f"   ‚úÖ Model saved ({model_size_mb:.1f} MB)")
        
        # 2. Salvar scalers
        self._save_scalers(out_dir, horizon)
        
        # 3. Salvar hist√≥ria do treino
        history_path = os.path.join(out_dir, "training_history.json")
        with open(history_path, "w") as f:
            # Converter arrays numpy para listas
            clean_history = {}
            for key, values in history.items():
                clean_history[key] = [float(v) for v in values]
            json.dump(clean_history, f, indent=2)
        
        # 4. Salvar m√©tricas
        metrics_path = os.path.join(out_dir, "metrics.json")
        with open(metrics_path, "w") as f:
            json.dump(metrics, f, indent=2)
        
        # 5. Salvar configura√ß√£o
        config_path = os.path.join(out_dir, "training_config.json")
        with open(config_path, "w") as f:
            json.dump(self.train_report["config"], f, indent=2)
        
        print(f"   ‚úÖ All artifacts saved to {out_dir}")
        
        # Atualizar relat√≥rio
        self.train_report["horizons"][str(horizon)] = {
            "model_dir": out_dir,
            "model_size_mb": model_size_mb,
            "test_samples": test_size,
            "metrics": {
                "mae": metrics.get("mae", 0),
                "rmse": metrics.get("rmse", 0)
            }
        }
    
    def _save_scalers(self, out_dir: str, horizon: int):
        """Salva os scalers X e Y."""
        os.makedirs(out_dir, exist_ok=True)
        
        # Salvar scaler X
        scaler_x_path = os.path.join(out_dir, "scaler_X.pkl")
        joblib.dump(self.feature_builder.scaler_X, scaler_x_path)
        
        # Salvar scalers Y (por vari√°vel)
        y_scalers = self.feature_builder.get_y_scalers(horizon)
        if y_scalers:
            for var_name, scaler in y_scalers.items():
                scaler_path = os.path.join(out_dir, f"scaler_y_{var_name}.pkl")
                joblib.dump(scaler, scaler_path)
            print(f"   ‚úÖ Y scalers saved for {list(y_scalers.keys())}")
    
    def _update_horizon_report(self, horizon: int, metrics: Dict, train_size: int):
        """Atualiza o relat√≥rio com resultados do horizonte."""
        if str(horizon) not in self.train_report["horizons"]:
            self.train_report["horizons"][str(horizon)] = {}
        
        self.train_report["horizons"][str(horizon)].update({
            "train_samples": train_size,
            "evaluation_metrics": metrics,
            "completed_at": datetime.utcnow().isoformat()
        })
    
    def _cleanup_between_horizons(self):
        """Limpa mem√≥ria entre o treino de diferentes horizontes."""
        gc.collect()
        tf.keras.backend.clear_session()
        self._log_memory("After horizon cleanup")
    
    def _save_final_report(self):
        """Salva o relat√≥rio final de treino."""
        # Adicionar uso final de recursos
        final_mem = psutil.virtual_memory()
        self.train_report["final_resource_usage"] = {
            "memory_percent": float(final_mem.percent),
            "memory_available_gb": float(final_mem.available / 1e9),
            "timestamp": datetime.utcnow().isoformat()
        }
        
        # Adicionar resumo
        self.train_report["summary"] = {
            "total_horizons_trained": len(self.train_report["horizons"]),
            "successful_horizons": [
                h for h in self.train_report["horizons"].keys()
            ]
        }
        
        # Salvar relat√≥rio
        report_path = os.path.join(self.results_dir, "training_report.json")
        with open(report_path, "w") as f:
            json.dump(self.train_report, f, indent=2)
        
        print(f"\nüìò Training report saved: {report_path}")
    
    def _print_resource_summary(self):
        """Imprime resumo do uso de recursos."""
        print("\n" + "=" * 60)
        print("üìä RESOURCE USAGE SUMMARY")
        print("=" * 60)
        
        final_mem = psutil.virtual_memory()
        print(f"Final memory usage: {final_mem.percent:.1f}%")
        print(f"Available: {final_mem.available / 1e9:.1f} GB")
        
        # Verificar se h√° vazamentos de mem√≥ria
        initial_usage = self.train_report["resource_usage"].get("After initialization", {})
        final_usage = self.train_report["resource_usage"].get("After horizon cleanup", {})
        
        if initial_usage and final_usage:
            mem_increase = final_usage.get("percent", 0) - initial_usage.get("percent", 0)
            if mem_increase > 10:
                print(f"‚ö†Ô∏è  Memory increase: {mem_increase:.1f}% (possible leak)")
            else:
                print(f"‚úÖ Memory management: OK ({mem_increase:.1f}% change)")
        
        print("=" * 60)


# ------------------------------------------------------------
# Fun√ß√µes auxiliares para execu√ß√£o direta
# ------------------------------------------------------------

def validate_training_environment():
    """Valida se o ambiente est√° pronto para treino."""
    print("üîç Validating training environment...")
    
    issues = []
    
    # Verificar TensorFlow
    try:
        tf_version = tf.__version__
        print(f"   ‚úÖ TensorFlow {tf_version}")
    except Exception as e:
        issues.append(f"TensorFlow error: {e}")
    
    # Verificar mem√≥ria
    try:
        mem = psutil.virtual_memory()
        if mem.available < 1e9:  # Menos de 1GB dispon√≠vel
            issues.append(f"Low memory: {mem.available / 1e9:.1f} GB available")
        else:
            print(f"   ‚úÖ Memory available: {mem.available / 1e9:.1f} GB")
    except Exception as e:
        issues.append(f"Memory check error: {e}")
    
    # Verificar diret√≥rios
    required_dirs = ["data", "models", "results"]
    for dir_name in required_dirs:
        if os.path.exists(dir_name):
            print(f"   ‚úÖ Directory exists: {dir_name}")
        else:
            issues.append(f"Missing directory: {dir_name}")
    
    if issues:
        print("\n‚ö†Ô∏è  Validation issues found:")
        for issue in issues:
            print(f"   ‚Ä¢ {issue}")
        return False
    else:
        print("‚úÖ Environment validation passed")
        return True


def create_github_free_config():
    """Cria configura√ß√£o otimizada para GitHub Free."""
    config = {
        "paths": {
            "data_dir": "data",
            "model_dir": "models/github_free",
            "results_dir": "results/github_free"
        },
        "targets": {
            "primary": ["V", "Bz", "n"],
            "secondary": ["Bx", "By", "Bt"]
        },
        "horizons": [1, 3, 6],
        "training": {
            "main_lookback": 12,  # Reduzido
            "batch_size": 16,     # Reduzido
            "max_epochs": 30,     # Reduzido
            "val_split": 0.15,
            "test_split": 0.15
        },
        "model": {
            "type": "lightweight",  # Modelo leve
            "lstm_units": [32],
            "dense_units": [16],
            "dropout_rate": 0.2
        }
    }
    
    # Salvar config tempor√°ria
    import yaml
    config_path = "config_github_free.yaml"
    with open(config_path, "w") as f:
        yaml.dump(config, f)
    
    print(f"‚úÖ GitHub Free config created: {config_path}")
    return config_path


# ------------------------------------------------------------
# Execu√ß√£o principal
# ------------------------------------------------------------

if __name__ == "__main__":
    print("=" * 60)
    print("üß™ HAC v6 TRAINING SCRIPT - CORRECTED")
    print("=" * 60)
    
    try:
        # Validar ambiente
        if not validate_training_environment():
            print("\n‚ö†Ô∏è  Environment validation failed. Creating GitHub Free config...")
            config_path = create_github_free_config()
        else:
            config_path = "config.yaml"
        
        # Criar e executar trainer
        trainer = HACTrainer(config_path)
        trainer.run()
        
        print("\n" + "=" * 60)
        print("üéâ TRAINING PIPELINE COMPLETED SUCCESSFULLY!")
        print("=" * 60)
        
        # Imprimir resumo final
        if trainer.train_report.get("horizons"):
            print("\nüìà TRAINING SUMMARY:")
            for horizon, data in trainer.train_report["horizons"].items():
                metrics = data.get("metrics", {})
                print(f"   Horizon {horizon}h:")
                print(f"     ‚Ä¢ MAE:  {metrics.get('mae', 'N/A'):.4f}")
                print(f"     ‚Ä¢ RMSE: {metrics.get('rmse', 'N/A'):.4f}")
                print(f"     ‚Ä¢ Model: {data.get('model_size_mb', 'N/A'):.1f} MB")
        
        print("\n‚ú® Next steps:")
        print("   1. Check models/ directory for trained models")
        print("   2. Check results/ directory for training reports")
        print("   3. Use models for inference with correct scaling")
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Training interrupted by user")
        
    except Exception as e:
        print(f"\nüí• FATAL ERROR: {str(e)}")
        import traceback
        traceback.print_exc()
        exit(1)
